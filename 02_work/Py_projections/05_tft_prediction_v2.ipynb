{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563d3b08",
   "metadata": {},
   "source": [
    "TFT with information on (future) popualtion in each cohort and bundesland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c628309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3080\n",
      "Number of GPUs: 1\n",
      "CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available (for NVIDIA GPUs)\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if cuda_available:\n",
    "    # Get the name of the current GPU\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")\n",
    "\n",
    "    # Get the number of available GPUs\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs: {gpu_count}\")\n",
    "\n",
    "    # Check CUDA version\n",
    "    cuda_version = torch.version.cuda\n",
    "    print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pyreadr import read_r\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "np.Inf = np.inf\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import (\n",
    "    optimize_hyperparameters,\n",
    ")\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import EncoderNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49e8eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/data/simon/\"\n",
    "#data_path = r\"C:\\Users\\simon.sarcletti\\OneDrive - FH JOANNEUM\\FH Joanneum - DAT\\XX_Masterarbeit\\05_Empirical_work\\01_data\\02_work\"\n",
    "\n",
    "all_munip_pop = read_r(data_path + r\"all_municipalities_population.RData\")[\n",
    "    \"all_munip_pop\"\n",
    "]\n",
    "\n",
    "all_munip_pop[\"municipality_code\"] = all_munip_pop[\"municipality_code\"].astype(\"int64\")\n",
    "\n",
    "all_munip_pop[\"bundesland\"] = (\n",
    "    all_munip_pop[\"municipality_code\"]\n",
    "    .astype(str)     # in case it’s numeric\n",
    "    .str[0]          # first character\n",
    "    .astype(int)     # back to integer, if you want 1,2,… rather than \"1\",\"2\",…\n",
    ")\n",
    "\n",
    "static_data_path = r\"/data/simon/\"\n",
    "#static_data_path = r\"C:\\Users\\simon.sarcletti\\OneDrive - FH JOANNEUM\\FH Joanneum - DAT\\XX_Masterarbeit\\05_Empirical_work\\01_data\\01_original\"\n",
    "\n",
    "static_metadata = pd.read_csv(\n",
    "    static_data_path + r\"static_variables.csv\",\n",
    "    encoding=\"latin-1\",\n",
    "    sep=\";\",\n",
    "    decimal=\",\",\n",
    ")\n",
    "\n",
    "\n",
    "variable_metadata = read_r(data_path + r\"aut_forecast_bl_sex_age_group.RData\")[\"aut_forecast\"]\n",
    "variable_metadata = variable_metadata.rename(columns={\"age_group\": \"coarse_age_group\"})\n",
    "variable_metadata_training = variable_metadata[variable_metadata['year'] <= 2024]\n",
    "variable_metadata_prediction = variable_metadata[variable_metadata['year'] > 2024]\n",
    "\n",
    "group_cols = [\"year\", \"coarse_age_group\", \"sex\"]\n",
    "unique_age_sex_data = variable_metadata_training.drop_duplicates(subset=group_cols, keep='first')\n",
    "unique_age_sex_data_prediction = variable_metadata_prediction.drop_duplicates(subset=group_cols, keep='first')\n",
    "group_cols2 = [\"year\", \"bundesland\"]\n",
    "unique_bl_data = variable_metadata_training.drop_duplicates(subset=group_cols2, keep='first')\n",
    "unique_bl_data_prediction = variable_metadata_prediction.drop_duplicates(subset=group_cols2, keep='first')\n",
    "merged_data = pd.merge(\n",
    "    all_munip_pop,\n",
    "    static_metadata,\n",
    "    how=\"left\",\n",
    "    left_on=\"municipality_code\",\n",
    "    right_on=\"ID\",\n",
    ")\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    unique_age_sex_data[[\"year\", \"coarse_age_group\", \"sex\", \"smoothed_pop_per_age_group_sex\"]],\n",
    "    how=\"left\",\n",
    "    on= [\"coarse_age_group\", \"year\", \"sex\"]\n",
    ")\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    unique_bl_data[[\"year\", \"bundesland\", \"smoothed_pop_per_bl\"]],\n",
    "    how=\"left\",\n",
    "    on=[\"year\", \"bundesland\"]\n",
    ")\n",
    "# create an index col\n",
    "merged_data[\"index\"] = (\n",
    "    merged_data[\"municipality_code\"].astype(str)\n",
    "    + \"_\"\n",
    "    + merged_data[\"sex\"].round(0).astype(str)\n",
    "    + \"_\"\n",
    "    + merged_data[\"coarse_age_group\"]\n",
    ")\n",
    "# remove unnecessary columns\n",
    "merged_data = merged_data.drop(\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"ID\",\n",
    "        \"municipality_code\",\n",
    "        \"reg_code\",\n",
    "        \"municipality\",\n",
    "        \"sex\",\n",
    "        \"population\",\n",
    "    ]\n",
    ") # maybe remove \"Jahresbruttobezug_2023\" as well\n",
    "\n",
    "merged_data = merged_data[merged_data[\"year\"] >= 2004].copy()\n",
    "\n",
    "# create a new column with first three digits of index\n",
    "merged_data[\"reg_code\"] = merged_data[\"index\"].str[:3]\n",
    "\n",
    "merged_data = merged_data.rename(\n",
    "    columns={\"smoothed_population\": \"population\", \"coarse_age_group\": \"age_group\"}\n",
    ")\n",
    "merged_data[\"year\"] = pd.to_numeric(merged_data[\"year\"], downcast=\"integer\")\n",
    "\n",
    "# drop col 'klassifikation_palme95\n",
    "merged_data = merged_data.drop(columns=[\"klassifikation_palme95\"])\n",
    "\n",
    "static_categoricals = ['bundesland','Urban-Rural-Typologie','OeV-Güteklassen', 'Bezirkshauptstadt',\n",
    "       'schulen_ue250', 'umkreis_schulen', 'haltestelle_IbIII',\n",
    "       'haltestelle_umkreis', 'autobahnauffahrt', 'autobahnauffahrt_umkreis','umkreis_einpendler', 'reg_code',]\n",
    "\n",
    "static_reals = ['Index_Pendlersaldos_2022','anteil_ue75_2014',\n",
    "       'anteil_ue75_2024', 'durchschnittsalter', 'Jahresbruttobezug_2023',\n",
    "       'anteil_frauen_1534_gesamtbevölkerung',\n",
    "       'verkehrsleistung_personenkilometer_energiemosaik',\n",
    "       'handelsgebaeude_1000ew_gwr', 'kulturgebaeude_1000ew_gwr',]\n",
    "\n",
    "for col in static_categoricals:\n",
    "    merged_data[col] = merged_data[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34607b",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad7f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"/data/lightning_logs/lightning_logs/version_1/checkpoints/epoch=49-step=2500.ckpt\"\n",
    "\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1349e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_length = 25\n",
    "max_prediction_length = 11\n",
    "\n",
    "# 1) grab the last 24 months of history\n",
    "encoder_data = merged_data[lambda df: df.year > df.year.max() - max_encoder_length]\n",
    "\n",
    "last_data = merged_data[lambda x: x.year == x.year.max()]\n",
    "\n",
    "decoder_data = pd.concat(\n",
    "    [\n",
    "        last_data.assign(year=lambda x, i=i: x['year'] + i)\n",
    "        for i in range(1, max_prediction_length + 1)\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "decoder_data = decoder_data.drop(columns=[\"smoothed_pop_per_bl\",\"smoothed_pop_per_age_group_sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fda560e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>bundesland</th>\n",
       "      <th>Urban-Rural-Typologie</th>\n",
       "      <th>OeV-Güteklassen</th>\n",
       "      <th>Bezirkshauptstadt</th>\n",
       "      <th>schulen_ue250</th>\n",
       "      <th>umkreis_schulen</th>\n",
       "      <th>haltestelle_IbIII</th>\n",
       "      <th>...</th>\n",
       "      <th>anteil_ue75_2014</th>\n",
       "      <th>anteil_ue75_2024</th>\n",
       "      <th>durchschnittsalter</th>\n",
       "      <th>Jahresbruttobezug_2023</th>\n",
       "      <th>anteil_frauen_1534_gesamtbevölkerung</th>\n",
       "      <th>verkehrsleistung_personenkilometer_energiemosaik</th>\n",
       "      <th>handelsgebaeude_1000ew_gwr</th>\n",
       "      <th>kulturgebaeude_1000ew_gwr</th>\n",
       "      <th>index</th>\n",
       "      <th>reg_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 - 9</td>\n",
       "      <td>2025</td>\n",
       "      <td>739.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>43.79</td>\n",
       "      <td>55672</td>\n",
       "      <td>10.881087</td>\n",
       "      <td>448559000</td>\n",
       "      <td>7.732119</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>10101_1.0_0 - 9</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 - 19</td>\n",
       "      <td>2025</td>\n",
       "      <td>789.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>43.79</td>\n",
       "      <td>55672</td>\n",
       "      <td>10.881087</td>\n",
       "      <td>448559000</td>\n",
       "      <td>7.732119</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>10101_1.0_10 - 19</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20 - 29</td>\n",
       "      <td>2025</td>\n",
       "      <td>933.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>43.79</td>\n",
       "      <td>55672</td>\n",
       "      <td>10.881087</td>\n",
       "      <td>448559000</td>\n",
       "      <td>7.732119</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>10101_1.0_20 - 29</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30 - 44</td>\n",
       "      <td>2025</td>\n",
       "      <td>1654.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>43.79</td>\n",
       "      <td>55672</td>\n",
       "      <td>10.881087</td>\n",
       "      <td>448559000</td>\n",
       "      <td>7.732119</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>10101_1.0_30 - 44</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45 - 54</td>\n",
       "      <td>2025</td>\n",
       "      <td>1028.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.99</td>\n",
       "      <td>9.73</td>\n",
       "      <td>43.79</td>\n",
       "      <td>55672</td>\n",
       "      <td>10.881087</td>\n",
       "      <td>448559000</td>\n",
       "      <td>7.732119</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>10101_1.0_45 - 54</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_group  year   population bundesland Urban-Rural-Typologie  \\\n",
       "0     0 - 9  2025   739.666667          1                   103   \n",
       "1   10 - 19  2025   789.333333          1                   103   \n",
       "2   20 - 29  2025   933.000000          1                   103   \n",
       "3   30 - 44  2025  1654.333333          1                   103   \n",
       "4   45 - 54  2025  1028.333333          1                   103   \n",
       "\n",
       "  OeV-Güteklassen Bezirkshauptstadt schulen_ue250 umkreis_schulen  \\\n",
       "0               C                 1             1               1   \n",
       "1               C                 1             1               1   \n",
       "2               C                 1             1               1   \n",
       "3               C                 1             1               1   \n",
       "4               C                 1             1               1   \n",
       "\n",
       "  haltestelle_IbIII  ... anteil_ue75_2014 anteil_ue75_2024 durchschnittsalter  \\\n",
       "0                 1  ...             8.99             9.73              43.79   \n",
       "1                 1  ...             8.99             9.73              43.79   \n",
       "2                 1  ...             8.99             9.73              43.79   \n",
       "3                 1  ...             8.99             9.73              43.79   \n",
       "4                 1  ...             8.99             9.73              43.79   \n",
       "\n",
       "   Jahresbruttobezug_2023 anteil_frauen_1534_gesamtbevölkerung  \\\n",
       "0                   55672                            10.881087   \n",
       "1                   55672                            10.881087   \n",
       "2                   55672                            10.881087   \n",
       "3                   55672                            10.881087   \n",
       "4                   55672                            10.881087   \n",
       "\n",
       "   verkehrsleistung_personenkilometer_energiemosaik  \\\n",
       "0                                         448559000   \n",
       "1                                         448559000   \n",
       "2                                         448559000   \n",
       "3                                         448559000   \n",
       "4                                         448559000   \n",
       "\n",
       "   handelsgebaeude_1000ew_gwr  kulturgebaeude_1000ew_gwr              index  \\\n",
       "0                    7.732119                   0.436491    10101_1.0_0 - 9   \n",
       "1                    7.732119                   0.436491  10101_1.0_10 - 19   \n",
       "2                    7.732119                   0.436491  10101_1.0_20 - 29   \n",
       "3                    7.732119                   0.436491  10101_1.0_30 - 44   \n",
       "4                    7.732119                   0.436491  10101_1.0_45 - 54   \n",
       "\n",
       "   reg_code  \n",
       "0       101  \n",
       "1       101  \n",
       "2       101  \n",
       "3       101  \n",
       "4       101  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b81007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_bl_data_prediction['bundesland'] = unique_bl_data_prediction['bundesland'].astype(float).astype(int).astype(str)\n",
    "decoder_data['bundesland'] = decoder_data['bundesland'].astype(str)\n",
    "decoder_data['year'] = decoder_data['year'].astype(int)\n",
    "unique_bl_data_prediction['year'] = unique_bl_data_prediction['year'].astype(int)\n",
    "decoder_data = pd.merge(\n",
    "    decoder_data,\n",
    "    unique_bl_data_prediction[['year', 'bundesland', 'smoothed_pop_per_bl']],\n",
    "    on=['year', 'bundesland'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "358546fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_age_sex_data_prediction['bundesland'] = unique_age_sex_data_prediction['bundesland'].astype(float).astype(int).astype(str)\n",
    "decoder_data['year'] = decoder_data['year'].astype(int)\n",
    "decoder_data = pd.merge(\n",
    "    decoder_data,\n",
    "    unique_bl_data_prediction[['year', 'bundesland', 'smoothed_pop_per_age_group_sex']],\n",
    "    on=['year', 'bundesland'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8495448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "\n",
    "static_categoricals = ['Urban-Rural-Typologie', 'OeV-Güteklassen', 'Bezirkshauptstadt',\n",
    "       'schulen_ue250', 'umkreis_schulen', 'haltestelle_IbIII',\n",
    "       'haltestelle_umkreis', 'autobahnauffahrt', 'autobahnauffahrt_umkreis','umkreis_einpendler', 'reg_code',]\n",
    "\n",
    "static_reals = ['Index_Pendlersaldos_2022','anteil_ue75_2014',\n",
    "       'anteil_ue75_2024', 'durchschnittsalter', 'Jahresbruttobezug_2023',\n",
    "       'anteil_frauen_1534_gesamtbevölkerung',\n",
    "       'verkehrsleistung_personenkilometer_energiemosaik',\n",
    "       'handelsgebaeude_1000ew_gwr', 'kulturgebaeude_1000ew_gwr',]\n",
    "\n",
    "for col in static_categoricals:\n",
    "    new_prediction_data[col] = new_prediction_data[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f74c2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions: (33840, 11, 7)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m     handles.handle,\n\u001b[32m    262\u001b[39m     lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m     quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:324\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[43mlibwriters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mwriters.pyx:73\u001b[39m, in \u001b[36mpandas._libs.writers.write_csv_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Build DataFrame\u001b[39;00m\n\u001b[32m     28\u001b[39m df_long = pd.DataFrame({\n\u001b[32m     29\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moriginal_index\u001b[39m\u001b[33m\"\u001b[39m: original_index,\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquantile\u001b[39m\u001b[33m\"\u001b[39m: quantile_column,\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m: year_column,\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction_column\n\u001b[32m     33\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mdf_long\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/v18y97/mt_pop_forecast/tft_prediction_with_dynamics_2025-2035.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Note: self.encoding is irrelevant here\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsvlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/common.py:157\u001b[39m, in \u001b[36mIOHandles.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\n\u001b[32m    152\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    153\u001b[39m     exc_type: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mBaseException\u001b[39;00m] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    154\u001b[39m     exc_value: \u001b[38;5;167;01mBaseException\u001b[39;00m | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    155\u001b[39m     traceback: TracebackType | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    156\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/torch-env/lib/python3.11/site-packages/pandas/io/common.py:144\u001b[39m, in \u001b[36mIOHandles.close\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28mself\u001b[39m.created_handles.remove(\u001b[38;5;28mself\u001b[39m.handle)\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.created_handles:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m     \u001b[43mhandle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m.created_handles = []\n\u001b[32m    146\u001b[39m \u001b[38;5;28mself\u001b[39m.is_wrapped = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "# actual prediction\n",
    "new_raw_predictions = best_tft.predict(\n",
    "    new_prediction_data,\n",
    "    mode=\"raw\",\n",
    "    return_x=True,\n",
    "    return_index=True,\n",
    "    trainer_kwargs=dict(accelerator=\"gpu\"),\n",
    ")\n",
    "\n",
    "arr = new_raw_predictions.output.prediction.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "n_samples, n_steps, n_quantiles = arr.shape  # (33840, 11, 7) if 11 years, 7 quantiles\n",
    "print(f\"Shape of predictions: {arr.shape}\")\n",
    "# Repeat each sample index\n",
    "original_index = np.repeat(new_raw_predictions.index[\"index\"], n_quantiles * n_steps)\n",
    "\n",
    "# Repeat quantiles and years\n",
    "quantiles = [\"0.01\", \"0.1\", \"0.25\", \"0.5\", \"0.75\", \"0.9\", \"0.99\"]\n",
    "quantile_column = np.tile(np.repeat(quantiles, n_steps), n_samples)\n",
    "year_column = np.tile(list(range(2025, 2025 + n_steps)), n_samples * n_quantiles)\n",
    "\n",
    "# Flatten prediction\n",
    "prediction_column = arr.flatten()\n",
    "\n",
    "# Build DataFrame\n",
    "df_long = pd.DataFrame({\n",
    "    \"original_index\": original_index,\n",
    "    \"quantile\": quantile_column,\n",
    "    \"year\": year_column,\n",
    "    \"prediction\": prediction_column\n",
    "})\n",
    "\n",
    "df_long.to_csv(\"/home/v18y97/mt_pop_forecast/tft_prediction_with_dynamics_2025-2035.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
